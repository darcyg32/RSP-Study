#Chapter_11 
- We have encountered several problems in this book where we couldn't find any efficient algorithm.
	- The theory of NP-completeness provides the tools needed to show that these problems are all, on some level, really the same problem.

- The key idea to demonstrating the hardness of a problem is that of *reduction*, or translation, between two problems.
- The following allegory of NP-completeness may help explain the idea.
	- A bunch of kids take turns fighting each other in the school yard to prove how "tough" they are.
		- Adam beats up Bill, who then beats up Dwayne.
		- So who if any among them qualifies as "tough"?
	- The truth is that there is no way to know without an external standard.
		- If I tell you that the action takes place in a kindergarten school yard, then the fight results don't mean very much.
		- But if I told you Dwayne was actually Dwayne Johnson (certified tough guy), both Adam and Bill must be at least as tough as he is.
	- In this telling, each fight represents a reduction, and Dwayne Johnson takes on the role of *satisfiability* - a certifiably hard problem.

- Reductions are algorithms that convert one problem into another.
- To describe them, we must be somewhat rigorous in our definitions.
	- An algorithmic *problem* is a general question, with parameters for input and conditions on what constitutes a satisfactory answer or solution.
	- An *instance* is a problem with the input parameters specified.
- The difference can be made clear by an example:

- ***Problem:*** The Traveling Salesman Problem (TSP)
- ***Input:*** A weighted graph *G*.
- ***Output:*** Which tour $(v_1,v_2,...,v_n)$ minimizes $\sum_{i=1}^{n-1}d[v_i,v_{i+1}] + d[v_n, v_1]$?

- Any weighted graph defines an instance of TSP.
	- Each particular *instance* has at least one minimum cost tour.
	- The general traveling salesman *problem* asks for an algorithm to find the optimal tour for any possible instance.

### 11.1.1 - The Key Idea
- Now consider two algorithmic problems, called *Bandersnatch* and *Bo-billy*.
	- Suppose that I gave you the following reduction/algorithm to solve the *Bandersnatch* problem:

Bandersnatch(*G*)
	Translate the input *G* to an instance *Y* of the Bo-billy problem.
	Call the subroutine Bo-billy to solve instance *Y*.
	Return the answer of Bo-Billy(*Y*) as the answer to Bandersnatch(*G*).

- This algorithm will *correctly* solve the Bandersnatch problem provided that the translation to Bo-billy always preserves the correctness of the answer.
	- In other words, provided that the translation has the property that for any translation *G*:
		- Bandersnatch(*G*) = Bo-billy(*Y*)

- A translation of instances from one type of problem to instances of another such that the answers are preserved is what we mean by a *reduction*.

- Now suppose this reduction translates instance *G* to *Y* in $O(P(n))$ time.
- There are two possible implications:
	- *If* my Bo-billy subroutine ran in $O(P'(n))$, this yields an algorithm to solve the Bandersnatch problem in $O(P(n)+P'(n))$, by translating the problem and then executing the Bo-billy routine to solve it.
	- *If* I know that $\Omega(P'(n))$ is a lower bound on computing Bandersnatch, meaning there definitely cannot exist a faster algorithm to solve it, then $\Omega(P'(n)-P(n))$ *must* be a lower bound to compute Bo-billy.
		- Why? If I *could* solve Bo-billy faster than this, the above reduction would violate my lower bound on solving Bandersnatch.
		- Because this is impossible, there can be no way to solve Bo-billy any faster than claimed.

- Essentially, this reduction shows that Bo-billy is no easier than Bandersnatch.
	- Therefore, if Bandersnatch is hard this means Bo-billy must also be hard.
- We will illustrate this point by giving a variety of problem reductions in this chapter.

- ***Take-Home Lesson:*
	- ***Reductions are a way to show that two problems are essential identical.*
	- ***A fast algorithm (or the lack of one) for one of these problems implies a fast algorithm (or the lack of one) for the other.*

### 11.1.2 - Decision Problems
- Reductions translate between problems so that their answers are identical in every problem instance.
- Problems differ in the *range* or *type* of possible answers.
	- The traveling salesman problem returns a permutation of vertices as the answer, while other types of problems may return strings or numbers as answers, perhaps restricted to positive numbers of integers.

- The simplest interesting class of problems have answers restricted to true and false.
	- These are *decision problems*.
- It proves convenient to reduce/translate answers between decision problems because both only allow true and false as possible answers.

- Fortunately, most interesting optimization problems can be phrased as decision problems that capture the essence of the computation.
	- For example, the travelling salesman decision problem is defined as:

- ***Problem:*** The Traveling Salesman Decision Problem (TSDP)
- ***Input:*** A weighted graph *G* and integer *k*.
- ***Output:*** Does there exist a TSP tour with cost $\leq k$?

- This decision version captures the heart of the traveling salesman problem, in that if you had a fast algorithm for the decision problem, you could do a binary search with different values of *k* and quickly home in on the cost of the optimal TSP solution.
	- With just a bit more cleverness, you could reconstruct the actual tour permutation using a fast solution to the decision problem.

- From now on I will generally talk about decision problems, because they prove easier to work with and still capture the power of the theory of NP-completeness.