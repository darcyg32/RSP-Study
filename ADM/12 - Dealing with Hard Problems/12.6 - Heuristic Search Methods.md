#Chapter_12 
- [[9.1 - Backtracking|Backtracking]] gave us a method to find the *best* of all possible solutions, as scored by a given objective function.
	- However, any algorithm searching all configurations is doomed to be impossible expensive on large instances.
- Heuristic search methods provide an alternate approach to difficult combinatorial optimization problems.

- In this section, I will discuss approaches to heuristic search.
	- The bulk of out attention will be devoted to simulated annealing, which I find to be the most reliable method to apply in practice.
- Heuristic search algorithms have an air of voodoo about them, but how they work and why one method can work better than another follows logically enough if you think them through.

- In particular, we will look at three different heuristic search methods:
	- Random sampling.
	- Gradient descent search.
	- Simulated annealing.
- The traveling salesman problem will be our ongoing example for comparing heuristics.

- All three heuristics share two common components:
	- *Solution Candidate Representation*:
		- This is a complete yet concise description of possible solutions for the problem, just like we used for backtracking.
			- For traveling salesman, the solution space consists of $(n-1)!$ elements - namely all possible circular permutations of the vertices.
		- We need a data structure that can represent each element of the solution space.
			- For TSP, the candidate solutions can naturally be represented using an array $S$ of $n-1$ vertices, where $S_i$ defines the $(i+1)st$ vertex on the tour starting from $v_1$.

	- *Cost Function*:
		- Search methods need a *cost* or *evaluation* function to assess the quality of each possible solution.
		- Our search heuristic identifies the element with the best score - either the highest or lowest depending upon the nature of the problem.
			- For TSP, the cost function for evaluating candidate solutions *S* just sums up the weights of all edges $S_i,S_{i+1})$, where $S_0$ and $S_n$ both denote $v_1$.

### 12.6.1 - Random Sampling
- The simplest approach to search in a solution space uses random sampling, also known as the *Monte Carlo method*.
	- We repeatedly construct random solutions and evaluate them, stopping as soon as we get a good enough solution, or (more likely) when we get tired or waiting.
	- We report the best solution found over the course of our sampling.

- True random sampling requires that we select elements from the solution space *uniformly at random*.
	- This means that each of the elements of the solution space must have an equal probability of being the next candidate selected.
- Such sampling can be subtle program.
	- Algorithms for generating random permutations, subsets, partitions, and graphs are discussed in Sections 17.4 - 17.7.

```C
void random_sampling(tsp_instance* t, int nsamples, tsp_solution* s) {
	tsp_solution s_now;    // Current tsp solution
	double best_cost;      // Best cost so far
	double cost_now;       // Current cost
	int i;                 // Counter


	initialize_solution(t->n, &s_now);
	best_cost = solution_cost(&s_now, t);
	copy_solution(&s_now, s);

	for (i = 1; i <= nsamples; i++) {
		random_solution(&s_now);
		cost_now = solution_cost(&s_now, t);

		if (cost_now < best_cost) {
			best_cost = cost_now;
			copy_solution(&s_now, s);
		}

		solution_count_update(&s_now, t);
	}
}
```

- When might random sampling do well?
	- *When there is a large proportion of acceptable answers*.
		- When good solutions are plentiful, a random search should find one quickly.
		- Finding prime numbers is such an example.
			- Roughly one out of every $\ln n$ integers is prime, so only a modest number of random samples need to be taken to discover primes that are several hundred digits long.

	- *When there is no coherence in the solution space.*
		- Random solution is the right thing to do when there is no sense of when we are getting *closer* to a solution.
		- Consider again the problem of hunting for a large prime number.
			- Primes are scattered quite arbitrarily among the integers.
			- Random sampling is as systematic as anything else would be.

- How does random sampling do on TSP? Pretty lousy.
	- The solution space consists almost entirely of mediocre to bad solutions, so quality grows very slowly with the amount of sampling/running time we invest.
- Figure 12.7 shows the arbitrary up-and-down movements of the generally poor quality solutions encountered using random sampling, so you can get a sense of how the score varied over each iteration.

![[Pasted image 20231220181913.png]]

- Most problems we encounter, like TSP, have relatively few good solutions and a highly coherent solution space.
	- More powerful heuristic search algorithms are required to hunt where the needle in the haystack is likely to be.

##### Stop and Think: Picking the Pair
- ***Problem:***
	- We need an efficient and unbiased way to generate random pairs of vertices to perform random vertex swaps.
	- Propose an efficient algorithm to generate elements from the $\binom{n}{2}$ *unordered* pairs on $\{1,...,n\}$ uniformly at random.

- ***Solution:*
	- Just pick two integers independently of each other.
	- Ignoring the ordering, by permuting the ordered pair to unordered pair $(x,y)$ where $x < y$, gives us a $2/n^2$ probability of generating each unordered pair of distinct elements.
		- If we happen to generate a pair $(x,x)$, we discard it and try again.
	- We will get unordered pairs uniformly at random in constant expected time by using the following algorithm:
```C
do {
	i = random_int(1, n);
	j = random_int(1, n);
	if (i > j) swap(&i, &j);
} while (i == j);
```

### 12.6.2 - Local Search
- A local search scans the *neighborhood* around elements in a solution space.
	- Think of each candidate solution *x* as a vertex, with a directed edge $(x, y)$ to every other candidate solution *y* that is a neighbour of *x*.
	- Our search proceeds from *x* to the most promising candidate in *x*'s neighbourhood.

- We certainly do *not* want to explicitly construct this neighborhood graph for any sizable solution space.
	- Think about TSP, which will have $(n-1)!$ vertices in this graph.
	- We are conducting a heuristic search precisely because we cannot hope to do this many operations in a reasonable amount of time.

- Instead, we want a general transition mechanism that takes us to a nearby solution by slightly modifying the current one.
	- Typical transition mechanisms include swapping a random pair of items or changing (inserting or deleting) a single item in the solution.

- A reasonable transition mechanism for TSP would be to swap the current tour positions of a random pair of vertices $S_i$ and $S_j$, as shown in Figure 12.8.
![[Pasted image 20231221122626.png]]
- This changes up to eight edges on the tour, deleting the four edges currently adjacent to $S_i$ and $S_j$, and adding their replacements.
	- The effect of such an incremental change on the quality of the solution can be computed incrementally, so the cost function evaluation takes time proportional to the size of the change (typically constant), which is a big win over being linear in the size of the solution.
- Even better might be to swap two *edges* on the tour with two others that replace it, since it may be easier to find moves that improve the cost of the tour.

- Local search heuristics start from an arbitrary element of the solution space, and then scan the neighborhood looking for a favorable transition to take.
	- In a favorable vertex swap, the four edges we insert are cheaper than the four edges we delete, a computation performed by the `transition` function.
	- In a greedy *hill-climbing* procedure, we try to find the top of a mountain (or alternatively, the lowest point in a ditch) by starting at some point and taking any step that leads in the direction we want to travel.
		- We repeat until we have reached a point where all our neighbours lead us in the wrong direction.
		- However, this may be the top of a hill, but it may not be the top of the *mountain*.
			- You might have to go down a bit before you can climb higher, which violates the requirement that each step must increase your score.
	- Hill climbing and closely related heuristics such as greedy search or local search are great at finding local optima quickly, but often fail to find the globally best solution.

```C
void hill_climbing(tsp_instance* t, tsp_solution* s) {
	double cost;     // Best cost so far
	double delta;    // Swap cost
	int i, j;        // Counters
	bool stuck;      // Did I get a better solution?

	initialize_solution(t->n, s);
	random_solution(s);
	cost = solution_cost(s, t);

	do {
		stuck = true;
		for (i = 1; i < t->n; i++) {
			delta = transition(s, t, i, j);
			if (delta < 0) {
				stuck = false;
				cost += delta;
			} else {
				transition(s, t, j, i);
			}
			solution_count_update(s, t);
		}
	} while (!stuck);
}
```

- When does local search do well?
	- *When there is a great coherence in the solution space.*
		- Hill climbing is at its best when the solution space is *convex*.
			- In other words, it consists of exactly one hill.
			- No matter where you start on the hill, there is always a direction to walk up until you are at the absolute global maximum.
		- Many natural problems have this property.
			- We can think of a binary search as starting in the middle of a search space, where exactly one of the two possible directions we can walk will get us closer to the target key.
		- The simplex algorithm for linear programming (see Section 16.6 (page 482)) is nothing more than hill climbing over the right solution space, yet it guarantees us the optimal solution to any linear programming problem.

	- *Whenever the cost of incremental evaluation is much cheaper than global evaluation.*
		- It costs $\Theta(n)$ to evaluate the cost of an arbitrary *n*-vertex candidate TSP solution, because we must sum up the cost of each edge in the circular permutation describing our tour.
			- Once that is found, however, the cost of the tour after swapping a given pair of vertices can be determined in constant time.
		- If we are given a very large value of *n* and a very small budget of how much time we can spend searching, we are better off using it to do a bunch of incremental evaluations than a few random samples, even if we are looking for a needle in a haystack.

- The primary drawback of a local search is that there isn’t anything more for us to do after we find the local optimum.
	- Sure, if we have more time we could restart from different random points, but in landscapes of many low hills we are unlikely to stumble on the optimum.

- How does local search do on TSP?
	- Much better than random sampling for a similar amount of time.
		- This best local search tour found on our hard 150-site TSP instance had a length of 15,715—improving the quality of our solution by almost a factor of three over random sampling.

- This is good, but not great.
	- You would not be happy to learn you are paying twice the taxes than you should be.
- Figure 12.9 illustrates the trajectory of a local search: repeated streaks from random tours down to decent solutions of fairly similar quality.
	- We need more powerful methods to get closer to the optimal solution.

![[Pasted image 20231221135959.png]]

### 12.6.3 - Simulated Annealing
- Simulated annealing is a heuristic search procedure that allows occasional transitions leading to more expensive (and hence inferior) solutions.
	- This may not sound like progress, but it helps keep our search from getting stuck in local optima.

- Simulated annealing is effective because it spends much more of its time working on good elements of the solution space than on bad ones, and because it avoids getting trapped in local optimum.

- As with a local search, the problem representation includes both a representation of the solution space and an easily computable cost function $C(s)$ measuring the quality of a given solution.
	- The new component is the *cooling schedule*, whose parameters govern how likely we are to accept a bad transition as a function of time.

- At the beginning of the search, we are eager to use randomness to explore the search space widely, so the probability of accepting a bad transition should be high.
	- As the search progresses, we seek to limit transitions to local improvements and optimizations.

- This cooling schedule can be regulated by the following parameters:
	- *Initial System Temperature*:
		- Typically $T_1=1$
	- *Temperature Decrement Function*:
		- Typically $T_i=\alpha*T_{i-1}$, where $0.8\leq\alpha\leq0.99$.
		- This implies an exponential decay in the temperature, as opposed to a linear decay.
	- *Number of iterations between temperature change*:
		- Typically, 1,000 iterations or so might be permitted before lowering the temperature.
		- Also, it generally pays to stay at a given temperature for multiple rounds so long as we are making progress there.
	- *Acceptance Criteria*:
		- A typical criterion is to accept any good transition, and also accept a bad transition whenever $e\frac{C(s_{i-1})-C(_i)}{k_BT}>r$, where *r* is a random number $0\leq r<1$.
		- The “Boltzmann” constant $k_B$ scales this cost function so that almost all transitions are accepted at the starting temperature.
	- *Stop Criteria*:
		- Typically, when the value of the current solution has not changed or improved within the last iteration or so, the search is terminated and the current solution reported.

- Creating the proper cooling schedule is a trial-and-error process of mucking with constants and seeing what happens.
	- It probably pays to start from an existing implementation of simulated annealing, so experiment with my full implementation at www.algorist.com.

- Compare the time/quality profiles of our three heuristics.
	- Simulated annealing does best of all.
- Figure 12.10 shows three runs from three different random initializations, each looking like a dying heartbeat as it converges to a minima.
	- Because they don’t get stuck in a local optimum, all three runs lead to much better solutions than the best hill-climbing result.
	- Further, the rapid plunges toward optimum show that it takes relatively few iterations to score most of the improvement.

![[Pasted image 20231221141233.png]]

- After ten million iterations simulated annealing gave us a solution of cost 7,212—only 10.4% over the optimum.
- Even better solutions are available to those willing to wait a bit longer.
	- Letting it run for one billion iterations (taking only 5 minutes, 21 seconds on my laptop) got the score down to 6,850, just 4.9% over the optimum.

- In expert hands, the best problem-specific heuristics for TSP will slightly outperform simulated annealing.
	- But here the simulated annealing solution works admirably.
	- It is my heuristic method of choice for optimization problems

##### Implementation
- The implementation follows the pseudocode quite closely:

```C
void anneal(tsp_instance* t, tsp_solution* s) {
	int x, y;                        // Pair of items to swap
	int i, j;                        // Counters
	bool accept_win, accept_loss;    // Conditions to accept transition
	double temperature;              // The current system temp
	double current_value;            // Value of current state
	double start_value;              // Value at start of loop
	double delta;                    // Value after swap
	double exponent;                 // Exponent for energy funct

	temperature = INITIAL_TEMPERATURE;

	initialize_solution(t->n, s);
	current_value = solution_cost(s, t);

	for (i = 1; i <= COOLING_STEPS; i++) {
		temperature *= COOLING_FRACTION;

		start_value = current_value;

		for (j = 1; j <= STEPS_PER_TEMP; j++) {
			// Pick indices of elements to swap
			x = random_int(1, t->n);
			y = random_int(1, t->n);

			delta = transition(s, t, x, y);
			accept_win = (delta < 0);     // Did swap reduce cost?

			exponent = (-delta / current_value) / (K * temperature);
			accept_loss = (exp(exponent) > random_float(0, 1));

			if (accept_win || accept_loss) {
				current_value += delta;
			} else {
				transition(s, t, x, y);   // Reverse transition
			}
			solution_count_update(s, t);
		}

		if (current_value < start_value) {    // Rerun at this temp
			temperature /= COOLING_FRACTION;
		}
	}
}
```

### 12.6.4 - Applications of Simulated Annealing
- We provide several examples to demonstrate how careful modeling of the state representation and cost function can lead to elegant simulated annealing solutions for real combinatorial search problems.
##### Maximum Cut
- The *maximum cut* problem seeks to partition the vertices of a weighted graph *G* into sets $V_1$ and $V_2$ to maximize the weight (or number) of edges with one vertex in each set.
	- For graphs that specify an electronic circuit, the maximum cut in the graph defines the largest amount of simultaneous data communication that can take place in the circuit.
	- As discussed in Section 19.6, maximum cut is NP-complete.

- How can we formulate maximum cut for simulated annealing?
	- The solution space consists of all $2^{n-1}$ possible vertex partitions.
		- We save a factor of two over all vertex subsets by fixing vertex $v_1$ to be on the left side of the partition.
			- The subset of vertices accompanying it can be represented using a bit vector.
	- The cost of a solution is the sum of the weights cut in the current configuration.

- A natural transition mechanism selects one vertex at random and moves it across the partition simply by flipping the corresponding bit in the bit vector.
	- The change in the cost function will be the weight of its old neighbours minus the weight of its new neighbours.
		- This can be computed in time proportional to the degree of the vertex.

- This kind of simple, natural modeling represents the right type of heuristic to seek in practice.

##### Independent Set
- An *independent set* of a graph *G* is a subset of vertices *S* such that there is no edge with both endpoints in *S*.
	- The maximum independent set of a graph is the largest vertex set that induces an empty (i.e. edgeless) subgraph.
	- Finding large independent sets arises in dispersion problems associated with facility location and coding theory, as discussed in Section 19.2 (page 589).

- The natural state space for a simulated annealing solution would consist of all $2^n$ possible subsets of the vertices, represented as a bit vector.
	- As with maximum cut, a simple transition mechanism would add or delete one vertex from S.

- One natural objective function for subset *S* might be 0 if the *S*-induced subgraph contains an edge, and *|S|* if it is indeed an independent set.
	- Such a function would ensure that we work towards an independent set at all times.
- However, this condition is so strict that we are liable to move in only a narrow portion of the total search space.
	- More flexibility and quicker objective function computations can result from allowing non-empty graphs at the early stages of cooling.\

- This can be obtained with an objective function like $C(S) = |S| − \lambda * m_S/T$, where $\lambda$ is a constant, *T* is the temperature, and $m_S$ is the number of edges in the subgraph induced by S.
	- This objective likes large subsets with few edges, and the dependence of $C(S)$ on *T* ensures that the search will eventually drive the edges out as the system cools.

##### Circuit Board Placement
- In designing printed circuit boards, we are faced with the problem of positioning modules (typically, integrated circuits) appropriately on the board.
- Desired criteria in a layout may include:
	- Minimizing the area or optimizing the aspect ratio of the board so that it properly fits within the allotted space; and,
	- Minimizing the total or longest wire length in connecting the components.
- Circuit board placement is representative of the type of messy, multicriterion optimization problems for which simulated annealing is ideally suited.

- Formally, we are given a collection of rectangular modules $r_1,...,r_n$, each with associated dimensions $h_i*l_i$.
	- Further, for each pair of modules $r_i,r_j$, we are given the number of wires $w_{ij}$ that must connect the two modules.
- We seek a placement of the rectangles that minimizes area and wire length, subject to the constraint that no two rectangles overlap each other.

- The state space for this problem must describe the positions of each rectangle on the board.
	- To make this discrete, these rectangles can be restricted to lie on vertices of an integer grid.

- Reasonable transition mechanisms include moving one rectangle to a different location, or swapping the position of two rectangles.

- A natural cost function might be: ![[Pasted image 20231221143450.png]]
- where $\lambda_{area}$,$\lambda_{wire}$, and $\lambda_{overlap}$ are weights governing the impact of these components on the cost function.
	- Presumably, $\lambda_{overlap}$ should be a decreasing function of temperature, so after gross placement it adjusts the rectangle positions to not overlap.