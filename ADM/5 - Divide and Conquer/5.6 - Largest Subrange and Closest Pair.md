#Chapter_5 
- Suppose you are tasked with writing the advertising copy for a hedge fund whose monthly performance this year was $[-17,5,3,-10,6,1,4,-3,8,1,-13,4]$.
	- You lost money for the year, but from May through October you had your greatest gains over any period, a net total of 17 units of gains.

- The largest subrange problem takes an array *A* of *n* numbers, and asks for the index pair *i* and *j* that maximises $S=\sum^{j}_{k=i}A[k]$.
	- Summing the entire array does not necessarily maximise *S* due to negative numbers.
	- Explicitly testing each possible interval start-end pair requires $\Omega (n^2)$ time.
	- Below we'll present a divide-and-conquer algorithm that runs in$O(n\log n)$ time.

- Suppose we divide the array *A* into left and right halves.
- Where can the largest subrange be?
	- It is either in the left half or the right half, or includes the middle.
- A recursive program to find the largest subrange between $A[l]$ and $A[r]$ can easily call itself to work on the left and right subproblems.
- How can we find the largest subrange spanning the middle, that is, spanning positions *m* and *m+1*?

![[Pasted image 20231125183314.png]]

- The key is to observe that the largest subrange centered spanning the middle will be the union of the largest subrange on the left ending on *m*, and the largest subrange on the right starting from *m+1*, as illustrated in Figure 5.3.
- The value $V_l$ of the largest such subrange on the left can be found in linear time with a sweep:
	LeftMinMaxRange(*A, l, m*)
		*S = M =* 0
		for *i = m* down to *l*
			*S = S + A\[i]*
			if (*S > M*) then *M = S*
		return M

- The corresponding value on the right can be found analogously.
- Dividing *n* into two halves, doing linear work, and recurring takes time $T(n)$, where $T(n)=2T(n/2)+\Theta(n)$.
	- Case 2 of the master theorem yields $T(n)=\Theta (n\log n)$.

- This general approach of "find the best on each size, and then what is straddling the middle" can be applied to other problems as well.

- Consider the problem of finding the smallest distance between pairs among a set of *n* points.
	- In one dimension, this problem is easy:
		- We say in [[4.1 - Applications of Sorting|Section 4.1]] that after sorting the points, the closest pair must be neighbors.
			- A linear-time sweep from left to right after sorting thus yields an $\Theta(n\log n)$ algorithm.
		- But we can replace this sweep by a divide-and-conquer algorithm.
			- The closest pair is defined by the left half of the points, the right half, or the pair in the middle. So the following algorithm must find it:
				ClosestPair(*A, l, r*)
					*mid* = *(l + r)/2*
					$l_{min}$ = ClosestPair(*A, l, mid*)
					$r_{min}$ = ClosestPair(*A, mid + 1, r*)
					return min($l_{min}, r_{min}, A[m+1]-A[m]$)
			- Because this does constant work per call, its running time is given by the recurrence: $T(n)=2*T(n/2)+O(1)$.
				- Case 1 of the master theorem tells us that $T(n)=\Theta (n)$.
	- This is still linear time and so might not seem very impressive, but let's generalize the idea to points in two dimensions.
		- After we sort the *n* (*x, y*) points according to their *x*-coordinates, the same property must be true: the closest pair is either two points on the left half, two points on the right, or it straddles left and right.
		- As shown in Figure 5.4, these straddling points had better be close to the dividing line (distance $d < min(l_{min}, r_{min})$) and also have very similar *y*-coordinates.
		- With clever bookkeeping, the closest straddling pair can be found in linear time, yielding a running time of $T(n)=2T(n/2)+\Theta(n) = \Theta(n\log n)$, as defined by Case 2 of the master theorem.

![[Pasted image 20231125190549.png]]
