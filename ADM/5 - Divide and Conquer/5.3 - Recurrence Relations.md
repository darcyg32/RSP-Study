#Chapter_5 
- Many divide-and-conquer algorithms have time complexities that are naturally modeled by recurrence relations.
- The ability to solve such recurrences is important to understand when divide-and-conquer algorithms perform well, and provides an important tool for analysis in general.

- What is a recurrence relation?
- It is an equation in which a function is defined in terms of itself.
	- The Fibonacci numbers are described by the recurrence relation $F_n = F_{n-1} + F_{n-2}$, together with the initial values $F_0 = 0$ and $F_1=1$, as will be discussed in Section 10.1.1.
	- Many other familiar functions are easily expressed as recurrences.
		- Any polynomial can be represented by a recurrence, such as the linear function: $a_n=a_{n-1}+1, a_1\to a_n=n$.
		- Any exponential can be represented by a recurrence:       $a_n=2a_{n-1}, a_1=1\to a_n=2^{n-1}$.
	- Finally, lots of weird functions that cannot be easily described using conventional notation can be represented naturally by a recurrence, for example: $a_n=na_{n-1},a_1=1\to a_n=n!$.
- This shows that recurrence relations are a very versatile way to represent functions.

- The self-reference property of recurrence relations is shared with recursive programs or algorithms, as the shared roots of both terms reflect.
- Essentially, recurrence relations provide a way to analyze recursive structures, such as algorithms.

### 5.3.1 - Divide-and-Conquer Recurrences
- A typical divide-and-conquer algorithm breaks a given problem into *a* smaller pieces, each of which is of size *n/b*.
	- It then spends $f(n)$ time to combine these subproblem solutions into a complete result.
- Let $T(n)$ denote the worst-case algorithm this algorithm takes to solve a problem of size *n*.
	- Then $T(n)$ is given by the following recurrence relation: 
		- $T(n)=a*T(n/b)+f(n)$

- Consider the following examples, based on algorithms we have previously seen:
	- *Mergesort*:
		- The running time of mergesort is governed by the recurrence $T(n)=2T(n/2)+O(n)$, since the algorithm divides the data into equal-sized halves and then spends linear time merging the halves after they are sorted.
		- In fact, this recurrence evaluates to $T(n)=O(n\lg n)$, just as we got by our previous analysis.
	- *Binary Search*:
		- The running time of binary search is governed by the recurrence $T(n)=T(n/2)+O(1)$, since at each step we spend constant time to reduce the problem to an instance half its size.
		- This recurrence evaluates to $T(n)=O(\lg n)$, just as we got by our previous analysis.
	- *Fast Heap Construction*:
		- The `bubble_down` method of heap construction (described in [[4.3 - Heapsort - Fast Sorting via Data Structures|Section 4.3.4]]) builds an *n*-element heap by constructing two *n/2* element heaps and then merging them with the root in logarithmic time.
		- The running time is thus governed by the recurrence relation $T(n)=2T(n/2)+O(\lg n)$.
		- This recurrence evaluates to $T(n)=O(n)$, just as we got by our previous analysis.

- Solving a recurrence means finding a nice closed form describing or bounding the result.
- We can use the *master theorem*, discussed in [[5.4 - Solving Divide-and-Conquer Recurrences|Section 5.4]], to solve the recurrence relations typically arising from divide-and-conquer algorithms.