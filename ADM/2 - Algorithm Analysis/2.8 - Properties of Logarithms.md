#Chapter_2 
- As we have seen, stating $b^x=y$ is equivalent to saying that $x=\log_by$.

- The *b* term is known as the *base* of the logarithm.
	- Three bases are of particular importance:
		- *Base* $b=2$:
			- The *binary logarithm*, usually denoted $\lg x$, is a base 2 logarithm.
			- We have seen how this base arises whenever repeated halving (i.e. binary search) or doubling (i.e. nodes in trees) occurs.
			- Most algorithmic applications of logarithms imply binary logarithms.
		- *Base* $b=e$:
			- The *natural logarithm*, usually denoted $\ln x$, is a base $e=2.71828...$ logarithm.
			- The inverse is the exponential function $e^x$ on your calculator.
			- Thus, $\exp(\ln x)=x$ and $\ln(\exp n) = x$.
		- *Base* $b=10$:
			- Less common today is the base-10 or *common logarithm*, usually denoted as $\log x$.

- We have already seen that $log_a(xy)=log_a(x)+log_a(y)$.

- The other important fact to remember is that is is easy to convert a logarithm from one base to another: $log_ab=\frac{log_cb}{log_ca}$.
	- Thus, changing the base of $\log b$ from base-*a* to base-*c* simply involves multiplying by $log_ca$.
		- It is easy to convert a common log function to a natural log function, and vice versa.

- Two implications of these properties of logarithms are important to appreciate from an algorithmic perspective:
	- *The base of the logarithm has no real impact on the growth rate*:
		- Changing the base of the log from *a* to *c* involves multiplying by $log_ca$.
		- This conversion factor is absorbed in the Big Oh notation whenever *a* and *c* are constants.
		- Thus, we are usually justified in ignoring the base of the logarithm when analyzing algorithms.
	- *Logarithms cut any function down to size*:
		- The growth rate of the logarithm of any polynomial function is $O(\lg n)$, as $\log_an^b=b*\log_an$.
		- The effectiveness of binary search is a consequence of this observation.
			- Note that performing a binary search on a sorted array of $n^2$ things requires only twice as many comparisons as a binary search on $n$ things.
		- Logarithms efficiently cut any function down to size.
			- It is hard to do arithmetic on factorials expect after taking logarithms, since $n!\to \log n! = \Theta(n\log n)$ provides another way logarithms pop up in algorithm analysis.