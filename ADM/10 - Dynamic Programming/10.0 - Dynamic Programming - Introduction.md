#Chapter_10
- The most challenging algorithmic problems involve optimization, where we seek to find a solution that maximizes or minimizes an objective function.
	- Traveling salesman is a classic optimization problem, where we seek the tour visiting all vertices of a graph at minimum total cost.
		- But as shown in Chapter 1, it is easy to propose TSP "algorithms" that generate reasonable-looking solutions but do not *always* produce the minimum cost tour.

- Algorithms for optimization problems require proof that they *always* return the best possible solution.
	- Greedy algorithms that make the best local decision at each step are typically efficient, but usually do not guarantee global optimality.
	- Exhaustive search algorithms that try all possibilities and select the best always produce the optimum result, but usually at a prohibitive cost in terms of time complexity.

- Dynamic programming combines the best of both worlds.
	- It gives us a way to design custom algorithms that systematically search all possibilities (thus guaranteeing correctness) while storing intermediate results to avoid recomputing (thus providing efficiency).
	- By storing the *consequences* of all possible decisions and using this information in a systematic way, the total amount of work is minimized.

- *After* you understand it, dynamic programming is probably the easiest algorithm design technique to apply in practice.

- Dynamic programming is a technique for efficiently implementing a recursive algorithm by storing partial results.
	- It requires seeing that a naive recursive algorithm computes the same subproblems over and over and over again.
		- In such a situation, storing the answer for each subproblem in a table to look up instead of recompute can lead to an efficient algorithm.
	- Dynamic programming starts with a recursive algorithm or definition.
		- Only after we have a correct recursive algorithm can we worry about speeding it up by using a results matrix.

- Dynamic programming is generally the right method for optimization problems on combinatorial objects that have an inherent *left-to-right* order among components.
	- Left-to-right objects include character strings, rooted trees, polygons, and integer sequences.
- Dynamic programming is best learned by carefully studying examples until things start to click.