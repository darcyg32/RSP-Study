#Chapter_10 
- Dynamic programming is essentially a tradeoff of space for time.
	- Repeatedly computing a given quantity can become a drag on performance.
		- If so, we are better off storing the results of the initial computation and looking them up instead of recomputing them.

- The tradeoff between space and time exploited in dynamic programming is best illustrated when evaluating [[5.3 - Recurrence Relations|recurrence relations]] such as the Fibonacci numbers.
	- We look at three different programs for computing them below.

### 10.1.1 - Fibonacci Numbers by Recursion
- The Fibonacci numbers are defined by the recurrence relation $F_n=F_{n-1}+F_{n-2}$, with basis cases $F_0=0$ and $F_1=1$.
	- Thus, $F_2=1, F_3=2$, and the series continues $3, 5, 8, 13, 21, 34, 55, 89, 144,...$.

- That they are defined by a recursive formula makes it easy to write a recursive program to compute the *n*th Fibonacci number.
	- A recursive function written in C looks like this:

```C
int fib_r(int n) {
	if (n == 0) {
		return 0;
	}

	if (n == 1) {
		return 1;
	}

	return fib_r(n - 1) + fib_r(n - 2);
}
```

- The course of execution for this recursive algorithm is illustrated by its *recursion tree*, as illustrated in Figure 10.1.
	- This tree is evaluated in a depth-first fashion, as are all recursive algorithms.

![[Pasted image 20231211113418.png]]

- Note that $F(4)$ is computed on both sides of the recursion tree, and $F(2)$ is computed five times in this small example.
	- The weight of all this redundancy becomes clear when you run the program.

- How much time does the recursive algorithm take to compute $F(n)$?
	- Since $F_{n+1}/F_n \approx \phi = (1+\sqrt{5})/2 \approx 1.61803$, this means that $F_n>1.6^n$ for sufficiently large *n*.
		- Since our recursion tree only has 0 and 1 as leaves, summing them up to get such a large number means we must have at least $1.6^n$ leaves or procedure calls.
		- This humble program takes exponential time to run!

### 10.1.2 - Fibonacci Numbers by Caching
- In fact, we can do much better.
	- We can explicitly store (or *cache*) the results of each Fibonacci computation $F(k)$ in a table data structure indexed by the parameter *k*, a technique also known as *memoization*.
- The key to implement the recursive algorithm efficiently is to explicitly check whether we already know a particular value before trying to compute it:

```C
#define MAXN 92       // Largest n for which F(n) fits in a long
#define UNKNOWN -1    // Contents denote an empty cell
long f[MAXN + 1];     // Array for caching fib values

long fib_c(int n) {
	if (f(n) == UNKNOWN) {
		f[n] = fib_c(n - 1) + fib_c(n - 2);
	}

	return f[n];
}

long fib_c_driver(int n) {
	int i;    // Counter

	f[0] = 0;
	f[1] = 1;

	for (i = 2; i <= n; i++) {
		f[i] = UNKNOWN;
	}

	return fib_c[n];
}
```

- To compute $F(n)$, we call `fib_c_driver(n)`.
	- This initializes our cache to the two values we initially know ($F(0)$ and $F(1)$) as well as the `UNKNOWN` flag for all the rest that we don't.
	- It then calls a look-before-crossing-the-street version of the recursive algorithm.

- This cached version runs instantly up to the largest value that can fit in a long integer.
	- The new recursion tree (Figure 10.2) explains why.
	- There is no meaningful branching, because only left-side calls do computation.
	- The right-side calls find what they are looking for in the cache and immediately return.

![[Pasted image 20231211204923.png]]

- What is the running time of this algorithm?
	- The recursion tree provides more of a clue than looking at the code.
	- In fact, it computes $F(n)$ in linear time because the recursive function `fib_c(k)` is called at most twice for each value $0\leq k \leq n-1$.

- This general method of explicitly caching (or *tabling*) results from recursive calls to avoid recomputation provides a simple way to get *most* of the benefits of full dynamic programming.
	- It is thus worth a careful look.

- In principle, storing partial results would have done absolutely no good for such recursive algorithms as *[[4.6 - Quicksort - Sorting by Randomization|quicksort]]*, *[[9.1 - Backtracking|backtracking]]*, and *[[7.8 - Depth-First Search|depth-first search]]*, because all the recursive calls made in these algorithms have distinct *parameter values*.
	- It doesn't pay to store something you will use once and never refer to again.

- Caching makes sense only when the space of distinct parameter values is modest enough that we can afford the cost of storage.
	- Since the argument to the recursive function `fib_c(k)` is an integer between 0 and *n*, there are only $O(n)$ values to cache.
		- A linear amount of space for an exponential amount of time is an excellent tradeoff.
	- But as we shall see, we can do even better by eliminating the recursion completely.

- ***Take-Home Lesson:*
	- ***Explicit caching of the results of recursive calls provides most of the benefits of dynamic programming, usually including the same runtime as the more elegant full solution.***

### 10.1.3 - Fibonacci Numbers by Dynamic Programming
- We can calculate $F_n$ in linear time more easily by explicitly specifying the order of evaluation of the recurrence relation:

```C
long fib_dp(int n) {
	int i;               // Counter
	long f[MAXN + 1];    // Array for caching values

	f[0] = 0;
	f[1] = 1;

	for (i = 2; i <= n; i++) {
		f[i] = f[i-1] + f[i-2];
	}

	return f[n];
}
```

- Observe that we have removed all recursive calls!
- We evaluate the Fibonacci numbers from smallest to biggest and store all the results, so we *know*that we have $F_{i-1}$ and $F_{i-2}$ ready whenever we need to compute $F_i$.
	- The linearity of this algorithm is now obvious.
	- Each of the *n* values is simply computed as the sum of two integers, in $O(n)$ total time and space.

- More careful study shows that we do not need to store all the intermediate values for the entire period of execution.
- Because the recurrence depends on two arguments, we only need to retain the last two values we have seen:

```C
long fib_ultimate(int n) {
	int i;             // Counter
	long back2 = 0;    // Last two values of f[n]
	long back1 = 1;
	long next;         // Placeholder for sum

	if (n == 0) {
		return 0;
	}

	for (i = 2; i < n; i++) {
		next = back1 + back2;
		back2 = back1;
		back1 = next;
	}

	return back1 + back2;
}
```

- This analysis reduces the storage demands to constant space with no asymptotic degradation in running time.

### 10.1.4 - Binomial Coefficients
- We now show how to compute *binomial coefficients* as another example of how to eliminate recursion by specifying the order of evaluation.
- The binomial coefficients are the most important class of counting numbers, where $\binom{n}{k}$ counts the number of ways to choose *k* things out of *n* possibilities.

- How do you compute binomial coefficients?
- First, $\binom{n}{k}=\frac{n!}{k!(n-k)!}$, so in principle you can compute them straight from factorials.
	- However, intermediate calculations can easily cause arithmetic overflow, even when the final coefficient fits within an integer.

- A more stable way is using the [[5.3 - Recurrence Relations|recurrence relation]] implicit in the construction of Pascal's triangle.
![[Pasted image 20231212194020.png]]
- Each number is the sum of the two numbers directly above it.
- The recurrence relation implicit in this is: $\binom{n}{k}=\binom{n-1}{k-1}+\binom{n-1}{k}$

- Why does this work?
- Consider whether the *n*th element appears in one of the $\binom{n}{k}$ subsets having *k* elements.
	- If it does, we can complete the subset by picking *k* − 1 other items from the remaining *n* − 1.
	- If it does not, we must pick all *k* items from the remaining *n* - 1.
	- There is no overlap between these cases, and all possibilities are included, so the sum counts all *k*-element subsets.

- No recurrence is complete without base cases.
- What binomial coefficient values do we know without computing them?
	- The left term of the sum eventually drives us down to $\binom{m}{0}$.
		- How many ways are there to choose zero things from a set?
			- Exactly one, the empty set.
		- If this is not convincing, then it is equally good to accept $\binom{m}{1}=m$ as the base case.
	- Together, these base cases and the recurrence define the binomial coefficients on all interesting values.

![[Pasted image 20231212194923.png]]

- Figure 10.3 demonstrates a proper evaluation order for the recurrence.
	- The initialized cells are marked $A-K$, denoting the order in which they were assigned values.
	- Each remaining cell is assigned the sum of the cell directly above it and the cell immediately above and to the left.
	- The triangle of cells marked 1 - 10 denote the evaluation order in computing $\binom{5}{4}=5$ using the following code:

```C
long binomial_coefficient(int n, int k) {
	int i, j;                       // Counters
	long bc[MAXN + 1][MAXN + 1];    // Binomial coefficient table

	for (i = 0; i <= n; i++) {
		bc[i][0] = 1;
	}

	for (j = 0; j <= n; j++) {
		bc[j][j] = 1;
	}

	for (i = 2; i <= n; i++) {
		for (j = 1; j < i; j++) {
			bc[i][j] = bc[i - 1][j - 1] + bc[i - 1][j];
		}
	}

	return bc[n][k];
}
```

