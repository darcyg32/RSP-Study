#Chapter_8 
- A *path* is a sequence of edges connecting two vertices.
	- There are typically an enormous number of possible paths connecting two nodes in any given road or social network.
- The path that minimizes the sum of edge weights, that is, the *shortest path*, is likely to be the most interesting, reflecting the fastest travel path or the closest kinship between the nodes.

- A shortest path from *s* to *t* in an unweighted graph can be identified using a [[7.6 - Breadth-First Search|breadth-first search]] from *s*.
	- The minimum-link path is recorded in the BFS tree, and hence provides the shortest path when all edges have equal weight.

- But BFS does *not* suffice to find the shortest path in weighted graphs.
	- The shortest weighted path might require a large number of edges, just as the fastest route from home to office may involve complicated shortcuts, as shown in Figure 8.7.

![[Pasted image 20231206151313.png]]

- This section will present two distinct algorithms for finding the shortest path in weighted graphs.

### 8.3.1 - Dijkstra's Algorithm
- Dijkstra's algorithm is the method of choice for finding shortest paths in an edge- and/or vertex-weighted graph.
	- Starting from a particular vertex *s*, it finds the shortest path from *s* to all other vertices in the graph, including the desired destination *t*.

- Suppose the shortest path from *s* to *t* in graph *G* passes through a particular intermediate vertex *x*.
	- Clearly, the best *s*-to-*t* path must contain the shortest path from *s* to *x* as its prefix, because if it doesn't, we can improve the path by starting with the shorter *s*-to-*x* prefix.
	- Thus, we must compute the shortest path from *s* to *x* before we find the path from *s* to *t*.

- Dijkstra's algorithm proceeds in a series of rounds, where each round establishes the shortest path from *s* to *some* new vertex.
	- Specifically, *x* is the vertex that minimizes $dist(s,v_i)+w(v_i,x)$ over all unfinished vertices $v_i$.
	- Here, $w(a,b)$ denotes the weight of the edge from vertex *a* to vertex *b*, and $dist(a,b)$ is the length of the shortest path between them,

- This suggests a dynamic programming-like strategy.
	- The shortest path from *s* to itself is trivial, so $dist(s, s)=0$ (assuming all edges are of positive weight).
	- If $(s, y)$ is the lightest edge incident to *s*, then $dist(s,y)=w(s,y)$.
	- Once we determine the shortest path to a node *x*, we check all the outgoing edges of *x* to see whether there is a shorter path from *s* through *x* to some unknown vertex.

ShortestPath-Dijkstra(*G, s, t*)
	$known=\{s\}$
	for each vertex *v* in *G*, $dist[v]=\infty$
	$dist[s]=0$
	for each edge $(s, v)$, $dist[v]=w(s,v)$
	$last = s$
	while ($last \neq t$)
		select $v_{next}$, the unknown vertex minimizing $dist[v]$
		for each edge $(v_{next}, x)$, $dist[x]=min[dist[x], dist[v_{next}]+w(v_{next},v)]$
		$last = v_{next}$
		$known=known\cup v_{next}$

- The basic idea is very similar to [[8.1 - Minimum Spanning Trees|Prim's algorithm]].
	- In each iteration, we add exactly one vertex to the tree of vertices for which we *know* the shortest path from *s*.
	- As in Prim's we keep track of the best path seen to date for all vertices outside the tree, and insert them in order of increasing cost.
- In fact, the *only* difference between Dijkstra's and Prim's algorithms is how they rate the desirability of each outside vertex.
	- In the minimum spanning tree algorithm we sought to minimize the weight of the next potential tree edge.
	- In shortest path, we want to identify the closest outside vertex (in shortest-path distance) to *s*.
		- This desirability is a function of both the new edge weight *and* the distance from *s* to the tree vertex it is adjacent to.

##### Implementation
```C
int dijkstra(graph* g, int start) {
	int i;                     // Counter
	edgenode* p;               // Temp pointer
	bool intree[MAXV + 1];     // Is the vertex in the tree yet?
	int distance[MAXV + 1];    // Cost of adding to tree
	int v;                     // Current vertex to process
	int w;                     // Candidate next vertex
	int dist;                  // Cheapest cost to enlarge tree
	int weight = 0;            // Tree weight

	// Initialization
	for (i = 1; i <= g->nvertices; i++) {
		intree[i] = false;     // No vertices in the tree initially
		distance[i] = MAXINT;  // Set the initial distances to infinity
		parent[1] = -1;        // Initialize parent array
	}

	distance[start] = 0;       // Distance to the source vertex is 0
	v = start;                 // Start from the source vertex

	// Main algorithm loop
	while (!intree[v]) {
		intree[v] = true;      // Mark the current vertex as in the tree

		// Output and acumulate the weight of the non-start edge added to the tree
		if (v != start) {
			printf("edge (%d,%d) in tree \n",parent[v],v);
			weight += dist;
		}

		// Process edges of the current vertex
		p = g->edges[v];
		while (p != NULL) {
			w = p->y;

			// Update distance if a shorter path is found
			if (distance[w] > (distance[v] + p->weight)) {
				distance[w] = distance[v] + p->weight;
				parent[w] = v;
			}
			
			p = p->next;
		}
		
		// Find the next vertex to add to the tree (with the smallest distance)
		dist = MAXINT;
		for (i = 1; i <= g->nvertices; i++) {
			if (!intree[i] && (dist > distance[i])) {
				dist = distance[i];
				v = i;
			}
		}
	}

	return weight;
}
```

- This algorithm defines a shortest-path spanning tree rooted in *s*.
- For unweighted graphs, this would be the BFS tree, but in general it provides the shortest path from *s* to all other vertices, not just *t*.
##### Analysis
- As implemented here, the time complexity is $O(n^2)$, exactly the same running time as a proper version of Prim's algorithm.
	- This is because, except for the extension condition, it *is* exactly the same algorithm as Prim's.

- The length of the shortest path from `start` to a given vertex *t* is exactly the value of `distance[t]`.
	- How do we use `dijkstra` to find the actual path?
	- We follow the backwards `parent` pointers from *t* until we hit `start` (or `-1` if no such path exists), exactly as was done in the BFS/DFS `find_path()` routine of [[7.6 - Breadth-First Search|Section 7.6.2]].

- Dijkstra works correctly only on graphs without negative-cost edges.
	- The reason is that during the execution, we may encounter an edge with weight so negative that it changes the cheapest way to get from *s* to some other vertex already in the tree.
- Fortunately, most applications don't have negative weights, making this discussion largely academic.
	- Floy's algorithm, discussed below, works correctly with negative-cost edges provided there are no negative cost *cycles*, which grossly distort the shortest-path structure.

##### Stop and Think: Shortest Path with Node Costs
- ***Problem***:
	- Suppose we are given a directed graph whose weights are on the vertices instead of the edges.
		- Thus, the cost of a path from *x* to *y* is the sum of the weights of all vertices on the path.
	- Give an efficient algorithm for finding shortest paths on vertex-weighted graphs.

- ***Solution*:
	- A natural idea would be to adapt Dijkstra's algorithm.
		- We would replace any reference to the weight of any directed edge $(x, y)$ with the weight of the destination vertex $y$.
	- However, a preferred approach might be to leave Dijkstra's algorithm intact and instead concentrate on constructing an edge-weighted graph on which Dijkstra's algorithm will give the desired answer.
		- Set the weight of each directed edge $(i, j)$ in the input graph to the cost of vertex *j*.
		- Dijkstra's algorithm now does the job.
	- Try to *design graphs, not algorithms*, as I will encourage in Section 8.7.

### 8.3.2 - All-Pairs Shortest Path
- Suppose you want to find the "center" vertex in a graph - the one that minimizes the longest or average distance to all the other nodes.
	- This might be the best place to start a new business.
- Or perhaps you need to know a graph's *diameter*, the largest shortest-path distance over all pairs of vertices.
	- This might correspond to the longest possible time it can take to deliver a letter or network packet.
- These and other applications require computing the shortest path between all pairs of vertices in a given graph.

- We could solve all-pairs shortest path by calling Dijkstra's algorithm from each of the *n* possible starting vertices. But Floyd's all-pairs shortest-path algorithm is a slick way to construct this *n x n* distance matrix from the original weight matrix of the graph.

- Floyd's algorithm is best employed on an adjacency matrix data structure, which is no extravagance since we must store all $n^2$ pairwise distances anyway.
- Our `adjacency_matrix` type allocates space for the largest possible matrix, and keeps track of how many vertices are in the graph:

```C
typedef struct {
	int weight[MAXV + 1][MAXV + 1]; // Adjacency / weight info
	int nvertices;                  // Number of vertices in graph
} adjacency_matrix;
```

- The critical issue in an adjacency matrix implementation is how we denote the edges absent from the graph.
	- A common convention for unweighted graphs denotes edges by 1 and non-edges by 0.
		- This gives exactly the wrong interpretation if the numbers denote edge weights, because the non-edges get interpreted as a free ride between vertices.
	- Instead, we should initialize each non-edge to `MAXINT`.
		- This way we can both test whether it is present and automatically ignore it in shortest-path computations.

- There are several ways to characterize the shortest path between two nodes in a graph.
- The Floyd-Warshall algorithm starts by numbering the vertices of the graph from 1 to *n*.
	- We use these numbers not to label the vertices, but to order them.
	- Define $W[i,j]^k$ to be the length of the shortest path from *i* to *j* using only vertices numbered from $1, 2, ..., k$ as possible intermediate vertices.

- What does this mean?
	- When $k=0$, we are allowed no intermediate vertices, so the only allowed paths are the original edges in the graph.
	- The initial all-pairs shortest-path matrix thus consists of the initial adjacency matrix.
	- We will perform *n* iterations, where the *k*th iteration allows only the first *k* vertices as possible intermediate steps on the path between each pair of vertices *x* and *y*.

- With each iteration, we allow a richer set of possible shortest paths by adding a new vertex as a possible intermediary.
- The *k*th vertex helps only if there is a shortest path that goes through *k*, so: $W[i,j]^k=min(W[i,j]^{k-1}, W[i,k]^{k-1}+W[k,j]^{k-1})$

- The implementation is as follows:
```C
void floyd(adjacency_matrix* g) {
	int i, j;         // Dimension counters
	int k;            // Intermediate vertex counter
	int through_k;    // Distance through vertex k

	for (k = 1; k <= g->nvertices; k++) {
		for (i = 1; i <= g->nvertices; i++) {
			for (j = 1; j <= g->nvertices; j++) {
				through_k = g->weight[i][k] + g->weight[k][j];
				if (through_k < g->weight[i][j]) {
					g->weight[i][j] = through_k;
				}
			}
		}
	}
}
```

- The Floyd-Warshall all-pairs shortest-path algorithm runs in $O(n^3)$ time, which is asymptotically no better than *n* calls to Dijkstra's algorithm.
	- However, the loops are so tight and the program so short that it runs better in practice.
	- It is notable as one of the rare graph algorithms that work better on adjacency matrices than adjacency lists.

- The output of Floyd's algorithm, as written, does not enable one to reconstruct the actual shortest path between any given pair of vertices.
	- These paths can be recovered if we retain a parent matrix *P* containing our choice of the last intermediate vertex used for each vertex pair $(x,y)$.
		- Say this value if *k*. The shortest path from *x* to *y* is the concatenation of the shortest path from *x* to *k* with the shortest path from *k* to *y*, which can be reconstructed recursively given the matrix *P*.
- Note, however, that most all-pairs applications only need the resulting distance matrix.
	- These are the jobs that Floyd's algorithm was designed for.

### 8.3.3 - Transitive Closure
- Floyd's algorithm has another important application, that of computing *transitive closure*.
- We are often interested in which vertices in a directed graph are reachable from a given node.
	- As an example, consider the *blackmail graph*, where there is a directed edge $(i,j)$ if person *i* has sensitive-enough private information on person *j* so that *i* can get *j* to do whatever they want. 
	- You wish to hire one of these *n* people to be your personal representative. Who has the most power in terms of blackmail potential?

- A simplistic answer would be the vertex of highest out-degree, but an even better representative would be the person who has blackmail chains leading to the most other parties.
	- Steve might only be able to blackmail Miguel directly, but if Miquel can blackmail everyone else then Steve is the person you want to hire.

- The vertices reachable from any single node can be computed using BFS or DFS.
	- But the complete set of relationships can be found using an all-pairs shortest path.
		- If the shortest path from *i* to *j* remains `MAXINT` after running Floyd's algorithm, you can be sure that no directed path exists from *i* to *j*.
		- Any vertex pair of weight less than `MAXINT` must be reachable, both in the graph-theoretic and blackmail senses of the world.

- Transitive closure is discussed in more detail in Section 18.5.