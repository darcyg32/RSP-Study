#Chapter_8 
- Clever [[6.0 - Hashing and Randomized Algorithms - Introduction|randomized algorithms]] have been developed for many different types of problems.
	- We have so far seen randomized algorithms for sorting (quicksort), searching (hashing), string matching (Rabin-Karp), and number-theoretic (primality testing) problems.
	- Here we expand this list to graph algorithms.

- The minimum-cut problem in graphs seeks to partition the vertices of graph *G* into sets $V_1$ and $V_2$ so that the smallest possible number of edges *(x, y)* span across these two sets, meaning $x\in V_1$ and $y\in V_2$.
	- Identifying the minimum cut often arises in network reliability analysis: What is the smallest failure set whose deletion will disconnect the graph?

- Suppose the minimum cut *C* in *G* is of size *k*, meaning that *k* edge deletions are necessary to disconnect *G*.
	- Each vertex *v* must therefore be connected to at least *k* other vertices, because if not there would be a smaller cut-set disconnecting *v* from the rest of the graph.
	- This implies that *G* must contain at least $kn/2$ edges, where *n* is the number of vertices, because each edge contributes one to the degree of exactly two degrees.

- A *contraction* operation for edge *(x, y)* collapses vertices *x* and *y* into a single merged vertex called (say) *xy*.
	- Any edge of the form *(x, z)* or *(y, z)* gets replaced by *(xy, z)*.
	- The upshot is that the number of vertices shrinks by one on an edge contraction.
	- The number of edges stays the same, although a self-loop *(xy, xy)* replaces *(x, y)*, and two copies of edge *(xy, z)* are created if both *(x, z)* and *(y, z)* were in *G* before the contraction.

- What happens to the size of the minimum cut after contracting *(x, y)* in *G*?
	- Each contraction reduces the space of possible $V_1, V_2$ partitions, since the new vertex *xy* cannot every be subdivided.
	- The critical observation is that the minimum-cut size is unchanged *unless* we contract one of the *k* edges of the optimal cut.
		- If we did not contract one of these cut edges, the minimum-cut size of the resulting graph might grow, because the best partition is no longer available.

- This suggests the following randomized algorithm.
- Pick a random edge of *G* and contract it.
	- Repeat a total of $n-2$ times, until we are left with a two-vertex graph with multiple parallel edges between them.
		- These edges describe a cut in the graph, although it might not be the smallest possible cut of *G*.
- We could repeat this entire procedure *r* times, and report the smallest cut we ever see as our proposed minimum cut.
	- Properly implemented, this contraction series for one given graph can be implemented in $O(nm)$ time, resulting in a Monte Carlo algorithm with $O(rmn)$ time, but no guarantee of an optimal solution.

- What are the chances of success on any given iteration?
- Consider the initial graph.
	- A contraction of a random edge *e* preserves the minimum cut *C* provided *e* is not one of the *k* cut edges.
	- Since *G* has at least $kn/2$ edges, the probability $p_i$ of a successful *i*th edge contraction is: $p_i\geq1-\frac{k}{k(n-1+2)/2}=1-\frac{2}{n-i+1}=\frac{n-i-1}{n-i+1}$
		- The odds on success for all but the last few contractions in a large graph are strongly in our favor.

- To end up with a minimum cut *C* for a particular run, we must succeed on every one of our $n-2$ contractions, which occurs with probability: $\prod^{n-2}_{i-1}p_i=\prod^{n-2}_{i-1}\frac{n-i-1}{n-i+1}=\frac{2}{n(n-1)}$.
	- The product cancels magically, and leaves a success probability of $\Theta(1/n^2)$.
- This isn't very large, but if we run $r=n^2\log n$ times it becomes very likely we will stumble upon the minimum cut at least once.

- ***Take-Home Lesson***:
	- ***The key to success in any randomized algorithm is setting up a situation where we can bound our probability of success.*
	- ***The analysis here can be tricky, but the resulting algorithms are often quite simple, as they are here.*
	- ***After all, complicated randomized algorithms likely become too difficult to analyze.*